"""
Comprehensive tests for the simplified approval flow without Redis complexity.

Tests each stage of the approval flow:
1. HITL node recognizes approval/disapproval
2. HITL node reflects that on state  
3. HITL node route decisions (approve/deny/invalid)
4. Agent node receives and processes state information
5. Agent node executes actions using state information

All tests use in-memory state management without external dependencies.
"""

import pytest
import asyncio
from unittest.mock import Mock, patch, AsyncMock
from backend.agents.hitl import (
    _process_confirmation_response,
    _process_hitl_response_node,
    hitl_node
)


class TestHITLRecognitionStage:
    """Test Stage 1: HITL node recognizes approval/disapproval"""
    
    def setup_method(self):
        """Setup test data for each test"""
        self.base_hitl_data = {
            "type": "confirmation",
            "prompt": "Send message to customer?",
            "options": {"approve": "approve", "deny": "deny"},
            "awaiting_response": True,
            "context": {
                "tool": "trigger_customer_message",
                "customer_info": {"id": "cust_123", "name": "John Smith", "email": "john@example.com"},
                "message_content": "Hello John, here's your update."
            }
        }
    
    @pytest.mark.asyncio
    async def test_recognizes_standard_approval_keywords(self):
        """Test recognition of standard approval keywords"""
        approval_inputs = ["approve", "yes", "y", "ok", "confirm", "proceed"]
        
        for input_text in approval_inputs:
            result = await _process_confirmation_response(
                self.base_hitl_data, 
                input_text.lower(), 
                input_text
            )
            
            assert result["success"] is True
            assert result["result"] == "approved"
            assert result["hitl_data"] is None  # Cleared on completion
            assert "âœ… Approved" in result["response_message"]
    
    @pytest.mark.asyncio
    async def test_recognizes_case_insensitive_approval(self):
        """Test case-insensitive approval recognition"""
        case_variants = ["APPROVE", "Approve", "YES", "Yes", "OK", "ok"]
        
        for input_text in case_variants:
            result = await _process_confirmation_response(
                self.base_hitl_data,
                input_text.lower(),  # response_text is lowercased
                input_text           # original_response preserves case
            )
            
            assert result["success"] is True
            assert result["result"] == "approved"
    
    @pytest.mark.asyncio 
    async def test_recognizes_standard_denial_keywords(self):
        """Test recognition of standard denial keywords"""
        denial_inputs = ["deny", "no", "n", "cancel", "abort", "stop"]
        
        for input_text in denial_inputs:
            result = await _process_confirmation_response(
                self.base_hitl_data,
                input_text.lower(),
                input_text
            )
            
            assert result["success"] is True
            assert result["result"] == "denied"
            assert result["hitl_data"] is None  # Cleared on completion
            assert "âŒ Cancelled" in result["response_message"]
    
    @pytest.mark.asyncio
    async def test_recognizes_partial_keyword_matches(self):
        """Test recognition of keywords within longer responses"""
        partial_matches = [
            ("I approve this action", "approved"),
            ("Please proceed with this", "approved"), 
            ("No thanks, cancel this", "denied"),
            ("I want to abort", "denied")
        ]
        
        for input_text, expected_result in partial_matches:
            result = await _process_confirmation_response(
                self.base_hitl_data,
                input_text.lower(),
                input_text
            )
            
            assert result["success"] is True
            assert result["result"] == expected_result
    
    @pytest.mark.asyncio
    async def test_handles_invalid_responses_with_context(self):
        """Test contextual handling of invalid responses"""
        invalid_inputs = ["maybe", "not sure", "later", "hello", "123", ""]
        
        for input_text in invalid_inputs:
            result = await _process_confirmation_response(
                self.base_hitl_data,
                input_text.lower(),
                input_text
            )
            
            assert result["success"] is False
            assert result["result"] is None
            assert result["hitl_data"] is not None  # HITL continues
            assert result["hitl_data"]["awaiting_response"] is False  # Will re-prompt
            assert f'"{input_text}"' in result["response_message"]  # Shows what was received
            assert "Did you mean to:" in result["response_message"]  # Contextual help
    
    @pytest.mark.asyncio
    async def test_uses_custom_approval_keywords(self):
        """Test using custom approval/denial keywords from options"""
        custom_hitl_data = {
            **self.base_hitl_data,
            "options": {"approve": "confirm", "deny": "reject"}
        }
        
        # Test custom approval
        result = await _process_confirmation_response(
            custom_hitl_data, "confirm", "confirm"
        )
        assert result["result"] == "approved"
        
        # Test custom denial
        result = await _process_confirmation_response(
            custom_hitl_data, "reject", "reject"
        )
        assert result["result"] == "denied"
        
        # Test invalid response shows custom keywords
        result = await _process_confirmation_response(
            custom_hitl_data, "maybe", "maybe"
        )
        assert "confirm" in result["response_message"]
        assert "reject" in result["response_message"]


class TestHITLStateReflectionStage:
    """Test Stage 2: HITL node reflects decisions on state"""
    
    def setup_method(self):
        self.base_state = {
            "messages": [
                {"role": "user", "content": "Send message to John"},
                {"role": "assistant", "content": "Send message to customer?"}
            ],
            "conversation_id": "conv_123",
            "hitl_data": {
                "type": "confirmation", 
                "prompt": "Send message?",
                "options": {"approve": "approve", "deny": "deny"},
                "awaiting_response": True,
                "context": {
                    "tool": "trigger_customer_message",
                    "customer_info": {"id": "cust_123", "name": "John Smith"},
                    "message_content": "Hello John"
                }
            }
        }
    
    @pytest.mark.asyncio
    async def test_approval_state_reflection(self):
        """Test state changes when approval is processed"""
        # Add human approval message
        approval_state = {
            **self.base_state,
            "messages": self.base_state["messages"] + [
                {"role": "human", "content": "approve"}
            ]
        }
        
        result = await _process_hitl_response_node(
            approval_state, 
            self.base_state["hitl_data"]
        )
        
        # Verify state reflection
        assert result["hitl_result"] == "approved"
        assert result["hitl_data"] is None  # Cleared 
        assert result["execution_data"] is not None  # Context passed for execution
        assert result["execution_data"]["tool"] == "trigger_customer_message"
        assert "âœ… Approved" in result["messages"][-1]["content"]
    
    @pytest.mark.asyncio 
    async def test_denial_state_reflection(self):
        """Test state changes when denial is processed"""
        denial_state = {
            **self.base_state,
            "messages": self.base_state["messages"] + [
                {"role": "human", "content": "deny"}
            ]
        }
        
        result = await _process_hitl_response_node(
            denial_state,
            self.base_state["hitl_data"]
        )
        
        # Verify state reflection
        assert result["hitl_result"] == "denied"
        assert result["hitl_data"] is None  # Cleared
        assert result["execution_data"] is None  # No execution for denial
        assert "âŒ Cancelled" in result["messages"][-1]["content"]
    
    @pytest.mark.asyncio
    async def test_invalid_response_state_reflection(self):
        """Test state changes when invalid response is processed"""
        invalid_state = {
            **self.base_state,
            "messages": self.base_state["messages"] + [
                {"role": "human", "content": "maybe later"}
            ]
        }
        
        result = await _process_hitl_response_node(
            invalid_state,
            self.base_state["hitl_data"]
        )
        
        # Verify state reflection for re-prompting
        assert result["hitl_result"] is None  # No decision made
        assert result["hitl_data"] is not None  # HITL continues
        assert result["hitl_data"]["awaiting_response"] is False  # Will re-prompt
        assert result["execution_data"] is None  # No execution
        assert "maybe later" in result["messages"][-1]["content"]  # Shows received input
    
    @pytest.mark.asyncio
    async def test_execution_data_extraction(self):
        """Test proper extraction of execution data from context"""
        context_data = {
            "tool": "trigger_customer_message",
            "customer_info": {
                "id": "cust_456", 
                "name": "Jane Doe",
                "email": "jane@example.com"
            },
            "message_content": "Hi Jane, your order is ready!",
            "message_type": "order_notification"
        }
        
        hitl_data = {
            **self.base_state["hitl_data"],
            "context": context_data
        }
        
        approval_state = {
            **self.base_state,
            "hitl_data": hitl_data,
            "messages": self.base_state["messages"] + [
                {"role": "human", "content": "yes"}
            ]
        }
        
        result = await _process_hitl_response_node(approval_state, hitl_data)
        
        # Verify execution data extraction
        execution_data = result["execution_data"]
        assert execution_data["tool"] == "trigger_customer_message"
        assert execution_data["customer_info"]["name"] == "Jane Doe"
        assert execution_data["message_content"] == "Hi Jane, your order is ready!"
        assert execution_data["message_type"] == "order_notification"


class TestHITLRouteDecisionStage:
    """Test Stage 3: HITL node route decisions"""
    
    @pytest.mark.asyncio
    async def test_approval_route_to_agent(self):
        """Test routing back to agent after approval"""
        state = {
            "messages": [{"role": "human", "content": "approve"}],
            "hitl_data": {
                "type": "confirmation",
                "prompt": "Send message?", 
                "options": {"approve": "approve", "deny": "deny"},
                "awaiting_response": True,
                "context": {"tool": "trigger_customer_message", "customer_info": {"id": "123"}}
            }
        }
        
        with patch('backend.agents.hitl.logger') as mock_logger:
            result = await hitl_node(state)
            
            # Should route back to agent with execution data
            assert result["hitl_result"] == "approved"
            assert result["hitl_data"] is None  # HITL complete
            assert result["execution_data"] is not None  # Agent can execute
    
    @pytest.mark.asyncio
    async def test_denial_route_to_agent(self):
        """Test routing back to agent after denial"""
        state = {
            "messages": [{"role": "human", "content": "no"}],
            "hitl_data": {
                "type": "confirmation",
                "prompt": "Send message?",
                "options": {"approve": "approve", "deny": "deny"}, 
                "awaiting_response": True,
                "context": {"tool": "trigger_customer_message"}
            }
        }
        
        result = await hitl_node(state)
        
        # Should route back to agent with cancellation
        assert result["hitl_result"] == "denied"
        assert result["hitl_data"] is None  # HITL complete
        assert result["execution_data"] is None  # No execution
    
    @pytest.mark.asyncio
    async def test_invalid_stays_in_hitl(self):
        """Test staying in HITL for invalid responses (re-prompting)"""
        state = {
            "messages": [{"role": "human", "content": "maybe"}],
            "hitl_data": {
                "type": "confirmation",
                "prompt": "Send message?",
                "options": {"approve": "approve", "deny": "deny"},
                "awaiting_response": True,
                "context": {"tool": "trigger_customer_message"}
            }
        }
        
        result = await hitl_node(state)
        
        # Should stay in HITL for re-prompting
        assert result["hitl_result"] is None  # No decision
        assert result["hitl_data"] is not None  # HITL continues
        assert result["hitl_data"]["awaiting_response"] is False  # Will show prompt again
        assert result["execution_data"] is None  # No execution


class TestAgentStateReceptionStage:
    """Test Stage 4: Agent node receives state information"""
    
    def test_agent_recognizes_approval_state(self):
        """Test agent correctly identifies approval state"""
        approval_state = {
            "hitl_result": "approved",
            "execution_data": {
                "tool": "trigger_customer_message",
                "customer_info": {"id": "123", "name": "John"},
                "message_content": "Hello"
            },
            "hitl_data": None
        }
        
        # Mock agent logic
        def mock_agent_routing(state):
            hitl_result = state.get("hitl_result")
            execution_data = state.get("execution_data")
            hitl_data = state.get("hitl_data")
            
            if hitl_result == "approved" and execution_data:
                return {"route": "execute", "action": execution_data["tool"]}
            elif hitl_result == "denied":
                return {"route": "cancel"}
            elif hitl_data:
                return {"route": "hitl"}
            else:
                return {"route": "normal"}
        
        result = mock_agent_routing(approval_state)
        assert result["route"] == "execute"
        assert result["action"] == "trigger_customer_message"
    
    def test_agent_recognizes_denial_state(self):
        """Test agent correctly identifies denial state"""
        denial_state = {
            "hitl_result": "denied", 
            "execution_data": None,
            "hitl_data": None
        }
        
        def mock_agent_routing(state):
            if state.get("hitl_result") == "denied":
                return {"route": "cancel"}
            return {"route": "other"}
        
        result = mock_agent_routing(denial_state)
        assert result["route"] == "cancel"
    
    def test_agent_recognizes_hitl_continuation_state(self):
        """Test agent recognizes when HITL interaction continues"""
        continuation_state = {
            "hitl_result": None,
            "execution_data": None,
            "hitl_data": {
                "type": "confirmation",
                "awaiting_response": False  # Will re-prompt
            }
        }
        
        def mock_agent_routing(state):
            if state.get("hitl_data"):
                return {"route": "hitl"}
            return {"route": "other"}
            
        result = mock_agent_routing(continuation_state)
        assert result["route"] == "hitl"


class TestAgentActionExecutionStage:
    """Test Stage 5: Agent executes actions using state information"""
    
    def setup_method(self):
        self.execution_data = {
            "tool": "trigger_customer_message",
            "customer_info": {
                "id": "cust_789",
                "name": "Alice Johnson", 
                "email": "alice@example.com"
            },
            "message_content": "Your appointment is confirmed for tomorrow.",
            "message_type": "appointment_confirmation"
        }
    
    def test_successful_action_execution(self):
        """Test successful execution of approved action"""
        # Mock successful message sending function
        def mock_send(**kwargs):
            return {"success": True, "message_id": "msg_123"}
        
        def mock_execute_approved_action(state, execution_data):
            # Simulate agent execution logic
            tool_name = execution_data["tool"]
            customer_info = execution_data["customer_info"]
            message_content = execution_data["message_content"]
            
            if tool_name == "trigger_customer_message":
                result = mock_send(
                    customer_id=customer_info["id"],
                    customer_name=customer_info["name"],
                    message_content=message_content
                )
                
                if result["success"]:
                    return {
                        **state,
                        "confirmation_result": "delivered",
                        "execution_data": None,  # Clear after execution
                        "hitl_result": None,     # Clear after execution
                        "messages": state.get("messages", []) + [{
                            "role": "assistant",
                            "content": f"âœ… Message sent to {customer_info['name']}!"
                        }]
                    }
        
        initial_state = {"messages": []}
        result = mock_execute_approved_action(initial_state, self.execution_data)
        
        # Verify execution results
        assert result["confirmation_result"] == "delivered"
        assert result["execution_data"] is None  # Cleared
        assert result["hitl_result"] is None     # Cleared
        assert "âœ… Message sent to Alice Johnson!" in result["messages"][-1]["content"]
        
        # Verify execution results (mock call verification removed for simplicity)
    
    def test_failed_action_execution(self):
        """Test handling of failed action execution"""
        # Mock failed message sending function
        def mock_send(**kwargs):
            return {"success": False, "error": "Email delivery failed"}
        
        def mock_execute_approved_action(state, execution_data):
            tool_name = execution_data["tool"]
            customer_info = execution_data["customer_info"]
            
            if tool_name == "trigger_customer_message":
                result = mock_send(
                    customer_id=customer_info["id"],
                    customer_name=customer_info["name"]
                )
                
                if not result["success"]:
                    return {
                        **state,
                        "confirmation_result": "failed",
                        "messages": state.get("messages", []) + [{
                            "role": "assistant",
                            "content": f"âŒ Failed to send message: {result['error']}"
                        }]
                    }
        
        initial_state = {"messages": []}
        result = mock_execute_approved_action(initial_state, self.execution_data)
        
        # Verify failure handling
        assert result["confirmation_result"] == "failed"
        assert "âŒ Failed to send message: Email delivery failed" in result["messages"][-1]["content"]
    
    def test_cancellation_handling(self):
        """Test handling of cancelled actions"""
        def mock_handle_cancellation(state):
            return {
                **state,
                "confirmation_result": "cancelled",
                "execution_data": None,
                "hitl_result": None,
                "messages": state.get("messages", []) + [{
                    "role": "assistant",
                    "content": "âœ… Action cancelled as requested. Is there anything else I can help you with?"
                }]
            }
        
        initial_state = {"messages": []}
        result = mock_handle_cancellation(initial_state)
        
        # Verify cancellation handling
        assert result["confirmation_result"] == "cancelled"
        assert result["execution_data"] is None
        assert result["hitl_result"] is None 
        assert "âœ… Action cancelled" in result["messages"][-1]["content"]
    
    def test_state_cleanup_after_execution(self):
        """Test proper state cleanup after action execution"""
        def mock_execute_with_cleanup(state, execution_data):
            return {
                **state,
                "confirmation_result": "delivered",
                # Verify all HITL/execution state is cleared
                "execution_data": None,
                "hitl_result": None,
                "hitl_data": None,
                "messages": state.get("messages", []) + [{"role": "assistant", "content": "Done!"}]
            }
        
        cluttered_state = {
            "messages": [],
            "execution_data": self.execution_data,
            "hitl_result": "approved",
            "hitl_data": {"some": "data"},
            "other_state": "preserved"
        }
        
        result = mock_execute_with_cleanup(cluttered_state, self.execution_data)
        
        # Verify cleanup
        assert result["execution_data"] is None
        assert result["hitl_result"] is None
        assert result["hitl_data"] is None
        assert result["confirmation_result"] == "delivered"
        assert result["other_state"] == "preserved"  # Other state preserved


class TestEndToEndApprovalFlow:
    """Test complete end-to-end approval flow"""
    
    @pytest.mark.asyncio
    async def test_complete_approval_flow(self):
        """Test complete flow from HITL prompt to action execution"""
        # Stage 1: Initial HITL prompt
        initial_state = {
            "messages": [{"role": "user", "content": "Send message to John"}],
            "hitl_data": {
                "type": "confirmation",
                "prompt": "Send message to customer?",
                "options": {"approve": "approve", "deny": "deny"},
                "awaiting_response": False,  # First run - will show prompt
                "context": {
                    "tool": "trigger_customer_message",
                    "customer_info": {"id": "123", "name": "John Smith"},
                    "message_content": "Hello John!"
                }
            }
        }
        
        # This would trigger interrupt() in real scenario
        # For test, we simulate the state after showing prompt
        prompt_shown_state = {
            **initial_state,
            "hitl_data": {**initial_state["hitl_data"], "awaiting_response": True}
        }
        
        # Stage 2: User approves
        user_approved_state = {
            **prompt_shown_state,
            "messages": prompt_shown_state["messages"] + [
                {"role": "human", "content": "approve"}
            ]
        }
        
        # Stage 3: HITL processes approval
        hitl_result = await _process_hitl_response_node(
            user_approved_state,
            user_approved_state["hitl_data"]
        )
        
        # Stage 4: Verify agent receives correct state
        assert hitl_result["hitl_result"] == "approved"
        assert hitl_result["execution_data"]["tool"] == "trigger_customer_message"
        assert hitl_result["hitl_data"] is None
        
        # Stage 5: Agent executes (simulated - no external dependencies)
        def simulate_agent_execution(state):
            execution_data = state["execution_data"]
            # Simulate successful execution
            return {
                **state,
                "confirmation_result": "delivered",
                "execution_data": None,  # Clear after execution
                "hitl_result": None,     # Clear after execution
                "messages": state.get("messages", []) + [{
                    "role": "assistant",
                    "content": f"âœ… Message sent to {execution_data['customer_info']['name']}!"
                }]
            }
        
        final_state = simulate_agent_execution(hitl_result)
        
        # Verify complete flow
        assert final_state["confirmation_result"] == "delivered"
        assert final_state["execution_data"] is None
        assert final_state["hitl_result"] is None
        assert "âœ… Message sent to John Smith!" in final_state["messages"][-1]["content"]
    
    @pytest.mark.asyncio
    async def test_complete_denial_flow(self):
        """Test complete flow from HITL prompt to cancellation"""
        initial_state = {
            "messages": [{"role": "user", "content": "Send message to John"}],
            "hitl_data": {
                "type": "confirmation",
                "prompt": "Send message?",
                "options": {"approve": "approve", "deny": "deny"},
                "awaiting_response": True,
                "context": {"tool": "trigger_customer_message"}
            }
        }
        
        # User denies
        user_denied_state = {
            **initial_state,
            "messages": initial_state["messages"] + [
                {"role": "human", "content": "no"}
            ]
        }
        
        # HITL processes denial
        hitl_result = await _process_hitl_response_node(
            user_denied_state,
            user_denied_state["hitl_data"]
        )
        
        # Verify denial handling
        assert hitl_result["hitl_result"] == "denied"
        assert hitl_result["execution_data"] is None
        assert hitl_result["hitl_data"] is None
        
        # Agent handles cancellation
        def simulate_agent_cancellation(state):
            return {
                **state,
                "confirmation_result": "cancelled",
                "hitl_result": None
            }
        
        final_state = simulate_agent_cancellation(hitl_result)
        assert final_state["confirmation_result"] == "cancelled"
    
    @pytest.mark.asyncio
    async def test_complete_invalid_response_flow(self):
        """Test complete flow with invalid response and re-prompting"""
        initial_state = {
            "messages": [{"role": "user", "content": "Send message"}],
            "hitl_data": {
                "type": "confirmation",
                "prompt": "Send message?",
                "options": {"approve": "approve", "deny": "deny"},
                "awaiting_response": True,
                "context": {"tool": "trigger_customer_message"}
            }
        }
        
        # User gives invalid response
        invalid_response_state = {
            **initial_state,
            "messages": initial_state["messages"] + [
                {"role": "human", "content": "maybe later"}
            ]
        }
        
        # HITL processes invalid response
        hitl_result = await _process_hitl_response_node(
            invalid_response_state,
            invalid_response_state["hitl_data"]
        )
        
        # Verify re-prompting
        assert hitl_result["hitl_result"] is None  # No decision made
        assert hitl_result["execution_data"] is None
        assert hitl_result["hitl_data"] is not None  # HITL continues
        assert hitl_result["hitl_data"]["awaiting_response"] is False  # Will re-prompt
        assert "maybe later" in hitl_result["messages"][-1]["content"]
        
        # Simulate second attempt with valid response
        second_attempt_state = {
            **hitl_result,
            "messages": hitl_result["messages"] + [
                {"role": "human", "content": "approve"}
            ]
        }
        
        second_result = await _process_hitl_response_node(
            second_attempt_state,
            second_attempt_state["hitl_data"]
        )
        
        # Verify second attempt succeeds
        assert second_result["hitl_result"] == "approved"
        assert second_result["hitl_data"] is None  # Completed

    @pytest.mark.asyncio
    async def test_multiple_invalid_attempts_then_approval(self):
        """Test user gives multiple invalid responses before finally approving"""
        initial_state = {
            "messages": [{"role": "user", "content": "Send urgent message to client"}],
            "hitl_data": {
                "type": "confirmation",
                "prompt": "Send urgent message to VIP client?",
                "options": {"approve": "approve", "deny": "deny"},
                "awaiting_response": True,
                "context": {
                    "tool": "trigger_customer_message",
                    "customer_info": {"id": "vip_456", "name": "Sarah Wilson", "email": "sarah@bigcorp.com"},
                    "message_content": "URGENT: Your contract requires immediate attention.",
                    "message_type": "urgent_notification",
                    "priority": "high"
                }
            }
        }
        
        # Invalid attempts sequence
        invalid_responses = ["maybe", "not sure", "hmm", "let me think"]
        current_state = initial_state
        
        for i, invalid_response in enumerate(invalid_responses):
            # User gives invalid response
            current_state = {
                **current_state,
                "messages": current_state["messages"] + [
                    {"role": "human", "content": invalid_response}
                ]
            }
            
            # HITL processes invalid response
            result = await _process_hitl_response_node(
                current_state,
                current_state["hitl_data"]
            )
            
            # Should still be prompting
            assert result["hitl_result"] is None
            assert result["execution_data"] is None
            assert result["hitl_data"] is not None
            assert result["hitl_data"]["awaiting_response"] is False
            assert f'"{invalid_response}"' in result["messages"][-1]["content"]
            
            # Prepare for next iteration
            current_state = {
                **result,
                "hitl_data": {**result["hitl_data"], "awaiting_response": True}
            }
        
        # Finally approve
        final_approval_state = {
            **current_state,
            "messages": current_state["messages"] + [
                {"role": "human", "content": "yes, approve it"}
            ]
        }
        
        final_result = await _process_hitl_response_node(
            final_approval_state,
            final_approval_state["hitl_data"]
        )
        
        # Should finally be approved with all context preserved
        assert final_result["hitl_result"] == "approved"
        assert final_result["hitl_data"] is None
        assert final_result["execution_data"]["customer_info"]["name"] == "Sarah Wilson"
        assert final_result["execution_data"]["priority"] == "high"
        assert "URGENT" in final_result["execution_data"]["message_content"]

    @pytest.mark.asyncio
    async def test_custom_keywords_flow(self):
        """Test flow with custom approval/denial keywords"""
        initial_state = {
            "messages": [{"role": "user", "content": "Schedule meeting with board"}],
            "hitl_data": {
                "type": "confirmation",
                "prompt": "Schedule board meeting for next week?",
                "options": {"approve": "confirm", "deny": "reject"},  # Custom keywords
                "awaiting_response": True,
                "context": {
                    "tool": "schedule_meeting",
                    "meeting_info": {
                        "title": "Board Meeting Q4 Review",
                        "attendees": ["CEO", "CTO", "CFO"],
                        "duration": "2 hours"
                    }
                }
            }
        }
        
        # Test invalid response with default keywords (should fail)
        invalid_state = {
            **initial_state,
            "messages": initial_state["messages"] + [
                {"role": "human", "content": "approve"}  # Wrong keyword
            ]
        }
        
        invalid_result = await _process_hitl_response_node(invalid_state, invalid_state["hitl_data"])
        assert invalid_result["hitl_result"] is None  # Should be invalid
        assert "approve" in invalid_result["messages"][-1]["content"]  # Shows what was received
        assert "confirm" in invalid_result["messages"][-1]["content"]  # Shows correct keyword
        
        # Test with correct custom keyword
        correct_state = {
            **invalid_result,
            "hitl_data": {**invalid_result["hitl_data"], "awaiting_response": True},
            "messages": invalid_result["messages"] + [
                {"role": "human", "content": "confirm"}  # Correct custom keyword
            ]
        }
        
        final_result = await _process_hitl_response_node(correct_state, correct_state["hitl_data"])
        assert final_result["hitl_result"] == "approved"
        assert final_result["execution_data"]["meeting_info"]["title"] == "Board Meeting Q4 Review"

    @pytest.mark.asyncio 
    async def test_messy_real_world_input_flow(self):
        """Test flow with messy real-world user input (punctuation, case, typos)"""
        initial_state = {
            "messages": [{"role": "user", "content": "Need to contact supplier ASAP"}],
            "hitl_data": {
                "type": "confirmation",
                "prompt": "Contact supplier about delayed shipment?",
                "options": {"approve": "approve", "deny": "deny"},
                "awaiting_response": True,
                "context": {
                    "tool": "send_supplier_email",
                    "supplier_info": {"name": "ABC Logistics", "email": "urgent@abclogistics.com"}
                }
            }
        }
        
        # Test various messy but valid inputs
        messy_valid_inputs = [
            "YES!",           # Caps with punctuation
            "  yes  ",        # Extra whitespace  
            "Ok, proceed.",   # Mixed case with punctuation
            "CONFIRM IT",     # Different valid keyword
            "y",              # Single letter
        ]
        
        for messy_input in messy_valid_inputs:
            test_state = {
                **initial_state,
                "messages": initial_state["messages"] + [
                    {"role": "human", "content": messy_input}
                ]
            }
            
            result = await _process_hitl_response_node(test_state, test_state["hitl_data"])
            
            # All should be recognized as approval despite being messy
            assert result["hitl_result"] == "approved", f"Failed to recognize '{messy_input}' as approval"
            assert result["execution_data"] is not None
            assert result["execution_data"]["supplier_info"]["name"] == "ABC Logistics"

    @pytest.mark.asyncio
    async def test_context_preservation_through_multiple_cycles(self):
        """Test that complex context data survives multiple HITL cycles"""
        complex_context = {
            "tool": "execute_complex_workflow",
            "workflow_data": {
                "steps": [
                    {"id": 1, "action": "validate_data", "params": {"strict": True}},
                    {"id": 2, "action": "process_payment", "params": {"amount": 1250.75, "currency": "USD"}},
                    {"id": 3, "action": "send_notifications", "params": {"channels": ["email", "sms", "slack"]}}
                ],
                "metadata": {
                    "created_by": "user_789",
                    "priority": "high",
                    "estimated_duration": "15 minutes",
                    "requires_audit": True,
                    "tags": ["finance", "urgent", "customer-facing"]
                },
                "dependencies": {
                    "external_apis": ["payment_gateway", "notification_service"],
                    "database_tables": ["transactions", "audit_log", "user_preferences"]
                }
            }
        }
        
        initial_state = {
            "messages": [{"role": "user", "content": "Execute the complex workflow"}],
            "hitl_data": {
                "type": "confirmation",
                "prompt": "Execute multi-step workflow with payment processing?",
                "options": {"approve": "approve", "deny": "deny"},
                "awaiting_response": True,
                "context": complex_context
            }
        }
        
        # Go through multiple invalid attempts
        current_state = initial_state
        invalid_attempts = ["what?", "explain more", "not sure about this"]
        
        for attempt in invalid_attempts:
            current_state = {
                **current_state,
                "messages": current_state["messages"] + [
                    {"role": "human", "content": attempt}
                ]
            }
            
            result = await _process_hitl_response_node(current_state, current_state["hitl_data"])
            
            # Context should be preserved in hitl_data
            preserved_context = result["hitl_data"]["context"]
            assert preserved_context["tool"] == "execute_complex_workflow"
            assert len(preserved_context["workflow_data"]["steps"]) == 3
            assert preserved_context["workflow_data"]["metadata"]["priority"] == "high"
            assert "payment_gateway" in preserved_context["workflow_data"]["dependencies"]["external_apis"]
            
            current_state = {**result, "hitl_data": {**result["hitl_data"], "awaiting_response": True}}
        
        # Finally approve
        final_state = {
            **current_state,
            "messages": current_state["messages"] + [
                {"role": "human", "content": "approve"}
            ]
        }
        
        final_result = await _process_hitl_response_node(final_state, final_state["hitl_data"])
        
        # All complex context should be preserved in execution_data
        execution_data = final_result["execution_data"]
        assert execution_data["workflow_data"]["steps"][1]["params"]["amount"] == 1250.75
        assert execution_data["workflow_data"]["metadata"]["requires_audit"] is True
        assert "customer-facing" in execution_data["workflow_data"]["metadata"]["tags"]

    @pytest.mark.asyncio
    async def test_edge_case_responses_flow(self):
        """Test flow with edge case user responses"""
        initial_state = {
            "messages": [{"role": "user", "content": "Delete old backups"}],
            "hitl_data": {
                "type": "confirmation", 
                "prompt": "Delete 500GB of old backup files?",
                "options": {"approve": "approve", "deny": "deny"},
                "awaiting_response": True,
                "context": {
                    "tool": "delete_backups",
                    "backup_info": {"count": 147, "total_size": "500GB", "oldest_date": "2023-01-01"}
                }
            }
        }
        
        # Test edge cases
        edge_cases = [
            ("", "empty response"),
            ("   ", "whitespace only"),
            ("ðŸ¤”", "emoji only"),
            ("????????????????", "question marks"),
            ("a" * 200, "very long nonsense"),
            ("approve deny yes no", "conflicting keywords"),
            ("ApPrOvE", "mixed case scrambled")
        ]
        
        for edge_input, description in edge_cases:
            test_state = {
                **initial_state,
                "messages": initial_state["messages"] + [
                    {"role": "human", "content": edge_input}
                ]
            }
            
            result = await _process_hitl_response_node(test_state, test_state["hitl_data"])
            
            if edge_input.lower().strip() == "approve":
                # Mixed case "ApPrOvE" should work
                assert result["hitl_result"] == "approved", f"'{edge_input}' ({description}) should be approved"
            elif edge_input == "ðŸ¤”" or edge_input == "" or edge_input.strip() == "":
                # Special handling for empty/emoji
                assert result["hitl_result"] is None, f"'{edge_input}' ({description}) should be invalid"
                assert result["hitl_data"] is not None, f"'{edge_input}' ({description}) should continue HITL"
            else:
                # Most edge cases should be invalid and re-prompt
                assert result["hitl_result"] is None, f"'{edge_input}' ({description}) should be invalid"
                assert result["hitl_data"] is not None, f"'{edge_input}' ({description}) should continue HITL"
                # Should show what was received in error message
                if edge_input and edge_input.strip():
                    assert edge_input[:20] in result["messages"][-1]["content"], f"Error message should show received input for '{edge_input}'"

    @pytest.mark.asyncio
    async def test_cancellation_at_different_stages(self):
        """Test user cancelling at various stages of the flow"""
        base_context = {
            "tool": "send_contract",
            "contract_info": {
                "client": "MegaCorp Inc",
                "value": "$2.5M",
                "duration": "3 years",
                "type": "enterprise_agreement"
            }
        }
        
        # Stage 1: Cancel on first prompt
        initial_state = {
            "messages": [{"role": "user", "content": "Send contract to MegaCorp"}],
            "hitl_data": {
                "type": "confirmation",
                "prompt": "Send $2.5M enterprise contract to MegaCorp?",
                "options": {"approve": "approve", "deny": "deny"},
                "awaiting_response": True,
                "context": base_context
            }
        }
        
        immediate_cancel_state = {
            **initial_state,
            "messages": initial_state["messages"] + [
                {"role": "human", "content": "cancel"}
            ]
        }
        
        immediate_result = await _process_hitl_response_node(immediate_cancel_state, immediate_cancel_state["hitl_data"])
        assert immediate_result["hitl_result"] == "denied"
        assert immediate_result["execution_data"] is None
        
        # Stage 2: Cancel after invalid attempts
        multi_stage_state = initial_state
        
        # Give some invalid responses first
        for invalid_response in ["hmm", "let me check"]:
            multi_stage_state = {
                **multi_stage_state,
                "messages": multi_stage_state["messages"] + [
                    {"role": "human", "content": invalid_response}
                ]
            }
            
            result = await _process_hitl_response_node(multi_stage_state, multi_stage_state["hitl_data"])
            multi_stage_state = {**result, "hitl_data": {**result["hitl_data"], "awaiting_response": True}}
        
        # Then cancel
        cancel_after_invalid_state = {
            **multi_stage_state,
            "messages": multi_stage_state["messages"] + [
                {"role": "human", "content": "abort"}
            ]
        }
        
        cancel_result = await _process_hitl_response_node(cancel_after_invalid_state, cancel_after_invalid_state["hitl_data"])
        assert cancel_result["hitl_result"] == "denied"
        assert cancel_result["execution_data"] is None
        # Context should still be preserved for logging/audit purposes in the final message
        assert "MegaCorp" in str(cancel_result.get("messages", []))

    @pytest.mark.asyncio
    async def test_execution_failure_recovery_flow(self):
        """Test what happens when execution fails and needs recovery"""
        initial_state = {
            "messages": [{"role": "user", "content": "Process refund for customer"}],
            "hitl_data": {
                "type": "confirmation",
                "prompt": "Process $500 refund for customer John Doe?",
                "options": {"approve": "approve", "deny": "deny"},
                "awaiting_response": True,
                "context": {
                    "tool": "process_refund",
                    "refund_info": {
                        "customer_id": "cust_789",
                        "customer_name": "John Doe",
                        "amount": 500.00,
                        "reason": "defective_product",
                        "order_id": "ORD_12345"
                    }
                }
            }
        }
        
        # User approves
        approved_state = {
            **initial_state,
            "messages": initial_state["messages"] + [
                {"role": "human", "content": "yes"}
            ]
        }
        
        approval_result = await _process_hitl_response_node(approved_state, approved_state["hitl_data"])
        
        # Verify approval went through
        assert approval_result["hitl_result"] == "approved"
        assert approval_result["execution_data"] is not None
        
        # Simulate execution failure
        def simulate_failed_execution(state):
            execution_data = state["execution_data"]
            return {
                **state,
                "confirmation_result": "failed",
                "execution_data": None,  # Clear even on failure
                "hitl_result": None,
                "messages": state.get("messages", []) + [{
                    "role": "assistant",
                    "content": f"âŒ Failed to process refund for {execution_data['refund_info']['customer_name']}: Payment gateway timeout. Please try again later."
                }],
                "error_details": {
                    "error_type": "payment_gateway_timeout",
                    "original_request": execution_data["refund_info"],
                    "retry_possible": True
                }
            }
        
        failed_state = simulate_failed_execution(approval_result)
        
        # Verify failure handling
        assert failed_state["confirmation_result"] == "failed"
        assert failed_state["execution_data"] is None  # Should be cleared
        assert failed_state["hitl_result"] is None     # Should be cleared
        assert "âŒ Failed to process refund" in failed_state["messages"][-1]["content"]
        assert failed_state["error_details"]["retry_possible"] is True
        
        # Simulate retry flow would start a new HITL interaction
        # (This would be handled by the agent deciding to retry)

    @pytest.mark.asyncio
    async def test_partial_keyword_matching_edge_cases(self):
        """Test edge cases in partial keyword matching"""
        initial_state = {
            "messages": [{"role": "user", "content": "Archive old documents"}],
            "hitl_data": {
                "type": "confirmation",
                "prompt": "Archive 1,200 documents older than 2 years?",
                "options": {"approve": "approve", "deny": "deny"},
                "awaiting_response": True,
                "context": {"tool": "archive_documents"}
            }
        }
        
        # Test tricky cases that might confuse word-based matching
        test_cases = [
            # Should be APPROVED (contains keywords as whole words)
            ("I approve this action", True, "contains approve as whole word"),
            ("Yes, let's proceed", True, "contains yes as whole word"),
            ("Ok to proceed", True, "contains ok as whole word"),
            ("Please confirm this", True, "contains confirm as whole word"),
            
            # Should be DENIED (contains keywords as whole words)
            ("No, don't do this", True, "contains no as whole word"),
            ("Cancel this operation", True, "contains cancel as whole word"),
            ("Stop right now", True, "contains stop as whole word"),
            
            # Should be INVALID (keywords not as whole words)
            ("maybe later", False, "maybe contains y but not as whole word"),
            ("not sure about this", False, "not contains no but not as whole word"),
            ("approval pending", False, "approval contains approve but not exact"),
            ("cannot proceed", True, "cannot + proceed -> proceed is valid approval keyword"),
            ("yokay", False, "yokay contains ok but not as whole word"),
            ("denominator", False, "denominator contains no but not as whole word"),
        ]
        
        for user_input, should_be_valid, description in test_cases:
            test_state = {
                **initial_state,
                "messages": initial_state["messages"] + [
                    {"role": "human", "content": user_input}
                ]
            }
            
            result = await _process_hitl_response_node(test_state, test_state["hitl_data"])
            
            is_valid = result["hitl_result"] is not None
            status = "âœ…" if is_valid == should_be_valid else "âŒ"
            
            assert is_valid == should_be_valid, f"{status} '{user_input}' -> Valid: {is_valid} (Expected: {should_be_valid}) - {description}"
            
            if should_be_valid:
                # Should have a decision and no continuing HITL data
                assert result["hitl_result"] in ["approved", "denied"]
                assert result["hitl_data"] is None
            else:
                # Should be invalid and continue HITL
                assert result["hitl_result"] is None
                assert result["hitl_data"] is not None
                assert f'"{user_input}"' in result["messages"][-1]["content"]


if __name__ == "__main__":
    pytest.main([__file__, "-v"]) 